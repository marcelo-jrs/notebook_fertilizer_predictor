{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = pd.read_csv('Crop_recommendation.csv')\n",
    "crop.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo Features e Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_and_map_labels(column):\n",
    "    # Crie um objeto LabelEncoder e ajuste-o aos valores originais\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(column)\n",
    "    \n",
    "    # Crie um dicionário de mapeamento de valores originais para valores codificados\n",
    "    label_mapping = dict(zip(encoded_labels, column))\n",
    "    \n",
    "    return encoded_labels, label_mapping\n",
    "\n",
    "# Suponha que você tenha uma coluna 'label' no DataFrame 'crop'\n",
    "encoded_labels, label_mapping = encode_and_map_labels(crop['label'])\n",
    "\n",
    "# Agora, você pode recuperar os valores originais a partir dos valores codificados\n",
    "original_labels = [label_mapping[label] for label in encoded_labels]\n",
    "\n",
    "print(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = crop[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]\n",
    "target = crop['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features,target,test_size = 0.2,random_state =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de aloritmos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(x_train,y_train)\n",
    "\n",
    "predicted_values = knn.predict(x_test)\n",
    "\n",
    "x = metrics.accuracy_score(y_test, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('K Nearest Neighbours')\n",
    "print(\"KNN precisão: \", x)\n",
    "\n",
    "print(classification_report(y_test,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(knn,features,target,cv=5)\n",
    "print('Cross validation: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisão do treino\n",
    "knn_train_accuracy = knn.score(x_train,y_train)\n",
    "print(\"Precisão do treino:\",knn.score(x_train,y_train))\n",
    "# Precisão do teste\n",
    "knn_test_accuracy = knn.score(x_test,y_test)\n",
    "print(\"Precisão do teste:\",knn.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiper-parâmetros para o KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_params = { 'n_neighbors' : [12,13,14,15,16,17,18],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "\n",
    "g_res = gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_res.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier(criterion=\"entropy\",random_state=2,max_depth=5)\n",
    "\n",
    "DT.fit(x_train,y_train)\n",
    "\n",
    "predicted_values = DT.predict(x_test)\n",
    "x = metrics.accuracy_score(y_test, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('Decision Tree')\n",
    "print(\"Decision Tree precisão: \", x*100)\n",
    "\n",
    "print(classification_report(y_test,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(DT, features, target,cv=5)\n",
    "print('Cross validation score: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino\n",
    "dt_train_accuracy = DT.score(x_train,y_train)\n",
    "print(\"Precisão do treino:\",DT.score(x_train,y_train))\n",
    "#Teste\n",
    "dt_test_accuracy = DT.score(x_test,y_test)\n",
    "print(\"Precisão do teste:\",DT.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "RF.fit(x_train,y_train)\n",
    "\n",
    "predicted_values = RF.predict(x_test)\n",
    "\n",
    "x = metrics.accuracy_score(y_test, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('RF')\n",
    "print(\"Random Forest precisão: \", x)\n",
    "\n",
    "print(classification_report(y_test,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(RF,features,target,cv=5)\n",
    "print('Cross validation: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino\n",
    "rf_train_accuracy = RF.score(x_train,y_train)\n",
    "print(\"Precisão do treino:\",RF.score(x_train,y_train))\n",
    "#Teste\n",
    "rf_test_accuracy = RF.score(x_test,y_test)\n",
    "print(\"Precisão do teste:\",RF.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navis Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NaiveBayes = GaussianNB()\n",
    "\n",
    "NaiveBayes.fit(x_train,y_train)\n",
    "\n",
    "predicted_values = NaiveBayes.predict(x_test)\n",
    "x = metrics.accuracy_score(y_test, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('Naive Bayes')\n",
    "print(\"Naive Bayes precisao: \", x)\n",
    "\n",
    "print(classification_report(y_test,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(NaiveBayes,features,target,cv=5)\n",
    "print('Cross validation: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_accuracy = NaiveBayes.score(x_train,y_train)\n",
    "print(\"Precisão do treino:\",NaiveBayes.score(x_train,y_train))\n",
    "nb_test_accuracy = NaiveBayes.score(x_test,y_test)\n",
    "print(\"Precisão do teste:\",NaiveBayes.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "XB = xgb.XGBClassifier()\n",
    "XB.fit(x_train,y_train)\n",
    "\n",
    "predicted_values = XB.predict(x_test)\n",
    "\n",
    "x = metrics.accuracy_score(y_test, predicted_values);\n",
    "acc.append(x)\n",
    "model.append('XGBoost')\n",
    "print(\"XGBoost precisão: \", x)\n",
    "\n",
    "print(classification_report(y_test,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(XB,features,target,cv=5)\n",
    "print('Cross validation score: ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XB_train_accuracy = XB.score(x_train,y_train)\n",
    "print(\"Precisão do treino:\",XB.score(x_train,y_train))\n",
    "\n",
    "XB_test_accuracy = XB.score(x_test,y_test)\n",
    "print(\"Precisão do teste:\",XB.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação entre os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14,7],dpi = 100, facecolor='white')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('ML Algorithms')\n",
    "sns.barplot(x = acc,y = model,palette='viridis')\n",
    "plt.savefig('plot.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['KNN', 'Decision Tree','Random Forest','Naive Bayes','XG Boost']\n",
    "Test = [knn_test_accuracy, dt_test_accuracy,rf_test_accuracy,\n",
    "        nb_test_accuracy, XB_test_accuracy]\n",
    "Train = [knn_train_accuracy,  dt_train_accuracy, rf_train_accuracy,\n",
    "         nb_train_accuracy, XB_train_accuracy]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20,7))\n",
    "X_axis = np.arange(len(label))\n",
    "plt.bar(X_axis - 0.2,Test, 0.4, label = 'Test', color=('midnightblue'))\n",
    "plt.bar(X_axis + 0.2,Train, 0.4, label = 'Train', color=('mediumaquamarine'))\n",
    "\n",
    "plt.xticks(X_axis, label)\n",
    "plt.xlabel(\"Algoritmos\")\n",
    "plt.ylabel(\"Precisão\")\n",
    "plt.title(\"Teste vs Treino\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando os gráficos fica fácil de perceber que o Naive Bayes foi o que teve a melhor precisão <br>\n",
    "Porém, quando um algoritmo atinge 100% de precisão, é necessário desconfiar <br>\n",
    "Pois é incomum e pode significar algum erro ou falta de dados para comparação <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open('classifier_crop.pkl','wb')\n",
    "pickle.dump(model[0],pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
